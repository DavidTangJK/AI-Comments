Hello, 

My name is Karla Ortiz, a concept artist, fine artist and illustrator based in San Francisco. My work has helped shape and create the worlds of blockbuster films including Marvel projects like Guardians of the Galaxy Vol. 3, Loki, The Eternals, Black Panther, Avengers :Infinity War, and Doctor Strange.  Below are excerpts from both of my written testimonies to the US. Senate Judiciary Subcommittee on Intellectual Property submitted on 07/07/23 and 08/08/23. These excerpts have been gathered and lightly edited for commentary to the U.S. Copyright Office. 

There are hundreds, maybe thousands, of concept artists and illustrators like me who work tirelessly to make the films, TV, video games, and other media that bring entertainment to millions of Americans every day.

I am no longer certain of my future as an artist—a new technology has emerged that represents an existential threat to our careers: generative artificial intelligence (“Generative AI”). 

 Generative AI has affected the value of every single artist I know, in foreseen and unforeseen ways. The skills we worked so hard to gain have now been automated. In a cruel twist of fate, that automation was only possible because our own works were taken —without consent, credit or compensation—to train generative AI systems. With generative AI, at the click of a button you can make digital replicas of artists, you can also generate countless images at quantities never before seen, and you can do so via a low monthly subscription. No singular human artist can ever hope to compete.

Because of this exploitative novelty, artists, myself included, have experienced a sudden shift in our industry. We have a harder time negotiating livable wages when there’s cheap software out there that can do our jobs. We have quietly seen an almost immediate devaluation of the skills we offer. Although no official studies have been made, reports of generative AI’s impact amongst peers at all levels in our industry continue to surface. For instance, accounts of legendary veterans in my industry asked to paint over AI generated imagery, essentially asking some of the best artists of our time to no longer paint the evocative imagery countless have seen and simply fix a visual error here and there for less pay. I’ve heard accounts of students losing out on internships because the position was now utilizing AIs, entry-level jobs being canceled, regular clients suddenly disappearing, usually busy times now being dry.

While the value of an artist is immeasurable, while we are all proud and confident in what we do, market forces simply do not agree. 

Especially with such a formidable cheaper and faster alternative to the costs of employing an artist. Again, if left to proliferate as is, being an artist may be something only a select few will ever be able to do.

In August and September of 2022, larger Generative AI models like Midjourney, Stable Diffusion and DALL-E are mainstream. In part because of my prior experience with generative AI, I did some research—I was horrified by what I found. I found that almost the entire body of my work, the work of almost every artist I know, and the work of hundreds of thousands of other artists, was taken without our consent, credit or compensation to train these for-profit technologies. I found out that once trained our work could not be forgotten. And to add insult to injury that these for-profit companies were not only permitting users to use our full names to generate imagery, but encouraging it. Some artists’ have had their names used as prompts a staggering number of times. For example, names of artists like the Polish artist Greg Rutkowski, had his name used as a prompt between Midjourney, Stability AI and the porn generator Unstable Diffusion, about 400,000 times as of December 2022. (And these are on the lower side of estimates).

I could not believe that an entire industry that so uniquely relied on ill-gotten data had suddenly emerged and was profiting without any regard to those it took data from;artists, creators and other rights holders . I connected with leaders in the AI/machine learning space to confirm what I had learned. Each and every AI/ML expert I talked to, from the founder of the Montreal AI Ethics Institute, to esteemed professors at the University of Chicago, to acclaimed researchers at the Distributed AI Research Institute were shocked at how exploitation fueled these synthetic media generators. Through speaking with these experts, I learned that due to the immense amount of data needed to power these models, it was very likely that every single model in the market right now contains huge amounts of copyrighted or otherwise licensed data. 

For example, the more popular models such as Stable Diffusion and Midjourney utilize a dataset created by LAION, a non-profit itself funded by Stability AI, which contains 5.8 billion image and text pairs taken indiscriminately from the web. LAION includes almost all of my fine art work, almost all of the work of my peers, the copyrighted works of my client without any regard to the rights of the artists themselves. Reporting indicates that these models may also be trained on other private data, such as medical records, nonconsensual porn, and violent images.

Of course, Generative AI models such as Stable Diffusion and Midjourney are hardly the entire Generative AI industry. Other industry leaders in the Artificial IntelligenceI/Machine Learning (“AI/ML”) media sector likewise obscure the sources of the data that fuels their models. But despite the secrecy, it has been revealed that AI companies of all stripes rely on copyrighted materials taken without permission in order to train their models. For example, researchers at the University of California, Berkeley have found that Open AI’s Chat GPT/GPT-4 was able to recite word by word entire sections of popular copyrighted books, a task that no model is able to do, unless it was trained on those books. 

OpenAI, even though it was founded as ostensibly an open-source company, has jealously guarded its training data, so it is difficult to tell just how much copyrighted or licensed materials were used as training data without the rightsholders’ consent.

Another example of the harms of secrecy, is Adobe’s Firefly, a model that tries to portray itself as "commercially safe.” Adobe claims that “[Firefly] was trained on Adobe Stock images, openly licensed content and public domain content, where copyright has expired”. It was reported by various media outlets, however, that Adobe Stock Contributors were never given the opportunity to opt-in for their work to be utilized for training, and offers Stock Contributors no way to opt-out their work for use as training data. This imposing denied Adobe Stock Contributors the opportunity to negotiate fair recompense for model ingestion of their work into models that may, and already are, competing against them. Currently Adobe itself has potentially utilized Generative AI works, including my own works, to train Adobe Firefly. Adobe has also refused to be fully transparent concerning the full contents of their training set, prohibiting rights holders from seeing if their works are included, especially concerning the vague category of “openly licensed works”.

It’s important to note that AI companies themselves acknowledge that the use of copyrighted material is an issue for generative AI models. 

Stability AI for example released the following statement when announcing their music model, Dance Diffusion, in September 23, 2022: “Because diffusion models are prone to memorization and overfitting, releasing a model trained on copyrighted data could potentially result in legal issues.” Unfortunately, while acknowledging the potential for harm in the audio space, Stability did not take the same approach with respect to visual or written arts.

These are only a few examples of how these Generative AI models violate the rights of artists and creatives en masse. The truth I discovered is that current Generative AI models rely on the nonconsensual use of ill-gotten copyrighted data of unwilling artists and the public’s data. This technology is already affecting creative fields like mine, not in a year or two from now, but right now. It is bad enough that this is being done without our consent, without any credit being offered, or without any compensation, but worse still, we are now forced to compete against these Generative AI models that were built upon our own work. No human being can outcompete a Generative AI model, due to the economies of scale: an AI is low cost and can generate a massive volume of ”good enough” products especially compared to a single artist.

AI companies are able to garner billions in funding and profit on models built from the hard work of artists and creators, while capturing the very market those artists and creators rely on in order to make a living. In any other context, such wide-scale misappropriation of the rights of so many people would be fundamentally unfair.

Therefore, that to reward models that normalize and reward such large-scale theft based generated work that is based on the work of artists and creatives, would be not only deeply unjust, but also immensely damaging to the concept of copyright itself, for why would copyright ever matter if it can simply be ingested and laundered by a model.

Thank you.
