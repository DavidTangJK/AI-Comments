
1. As described above, generative AI systems have the ability to produce material that would be copyrightable if it were created by a human author. What are your views on the potential benefits and risks of this technology? How is the use of this technology currently affecting or likely to affect creators, copyright owners, technology developers, researchers, and the public?  AI is essentially a toy for the public, by mixing copyrighted things into other things like Mario vs Hulk Hogan. Training AIs on copyrighted data without consent or compensation harms creators. Stronger attribution and data licensing norms are needed. Overall, maintaining humanity's indispensable role in imaginative works while establishing equitable norms around data usage, attribution and AI transparency will allow responsibly nurturing creativity in all its forms. But careful governance is needed to prevent exploitative externalities at the expense of human ingenuity and livelihoods.  Under no circumstances should AI be given copyright while all these models contain copyright data. Allowing copyright would be exploiting artists. 


2. Does the increasing use or distribution of AI-generated material raise any unique issues for your sector or industry as compared to other copyright stakeholders? Yes, individuals have fewer resources to withstand the loss of income from AI vs Studios. Anyone can make a lora(style) of someone's works and start uploading in their style and directly competing with that artist. Companies are already selling artist data at a minimum, not at the individuals prices, merely cents while they will sell those pieces for  bigger sums of money. This gives big studios/big companies to erase the need for an entire field of work or pile on work to senior level artists, without more pay usually. Big companies should not be allowed to use AI from beginning to end and still profit.  AI is hurting everyone downstream.

3. Please identify any papers or studies that you believe are relevant to this Notice. These may address, for example, the economic effects of generative AI on the creative industries or how different licensing regimes do or could operate to remunerate copyright owners and/or creators for the use of their works in training AI models. The Office requests that commenters provide a hyperlink to the identified papers. https://arxiv.org/pdf/2306.04141.pdf

4. Are there any statutory or regulatory approaches that have been adopted or are under consideration in other countries that relate to copyright and AI that should be considered or avoided in the United States?  (40) How important a factor is international consistency in this area across borders? Stronger attribution to preserve their recgonition and to aid downstream when working with AI. Artists not getting paid, or paid at a minimum, is a huge problem. Perhaps, a community rights clause like requiring represenation on corporate ethics boards to keep individuals from being taken advantage of. All models should be compulsory in royalities to artists, especially since these models are used for commericial. It's not right to take millions of artists work then sell it to the public at a premium while everyone who worked on these models got paid, everyone after gets paid but the artists never got paid. Limiting copyright on AI work keeps human input rather that the outright replacement of artists, exploiting them until the day humanity ends. Artists are some of the lowest paid people on the planet and these companies are parasitic in nature. 

5. Is new legislation warranted to address copyright or related issues with generative AI? If so, what should it entail? Specific proposals and legislative text are not necessary, but the Office welcomes any proposals or text for review.  AI generated content without significant human input in the product, meaning 80%+ should not be copyrightable. AI content should be free content unless it had significant human input behind it because there are now deepfake movies, ai videos that are riding off the back of artists. I also say this as a warning because people upload anything that comes to mind, it is essentially played with as a toy by many and uploaded in droves where they might have 6-20 different versions of the same thing. Without an artists work, this technology could not exist in any functioning capacity and the ecosystem is derived on parasitic needs. Due to so many IPs and individuals works being inside these machines, there needs to be a strengthening of Digital Rights Management. Forcing AI systems to uphold protections to stop unauthorizied scraping of people's content. More clarification on Fair Use/Transformative works for AI content due to the intent it needs to be treated as something one should not be making money off of unless it has significant human input, not at the prompt level and not at using the AI to fix the issues but afterwards. 


Training 

If your comment applies only to a specific subset of AI technologies, please make that clear.

6. What kinds of copyright-protected training materials are used to train AI models, and how are those materials collected and curated?
Here are some common practices: Data Scraping and Crawling: AI models may be trained on vast amounts of data collected through web scraping or crawling techniques. It's important to note that scraping copyrighted content without proper authorization can raise legal concerns and should be done in compliance with applicable copyright laws. They were scraped from popular art websites where the individuals posted their copyright work freely. They might have obtained lisences but I would doubt that as no companies have come forward saying they were given money for their lisenced work. They've also probably used some Creative Commons resources that require attribution for the use of their image but none was given. 

6.1. How or where do developers of AI models acquire the materials or datasets that their models are trained on? To what extent is training material first collected by third-party entities (such as academic researchers or private companies)? Pinterest, Artstation and Deviantart

6.2. To what extent are copyrighted works licensed from copyright owners for use as training materials? To your knowledge, what licensing models are currently being offered and used? I doubt any licesning for MJ, SD or Dall-E has ever taken place.  The only one who has done something close is Firefly from Adobe. 

6.3. To what extent is non-copyrighted material (such as public domain works) used for AI training? Alternatively, to what extent is training material created or commissioned by developers of AI models? I'm sure probably some of it because you can straight up ask it to create classic works in those styles of public domain pieces. 

6.4. Are some or all training materials retained by developers of AI models after training is complete, and for what purpose(s)? Please describe any relevant storage and retention practices. No, they are not retained but the issue isn't that they downloaded and saved it. The issue is that the AI has a perfect memory and does not forget these images and that is why you can use a 'style of studio ghibli' and they come up. Artists have been tags in their works, so the machine can recall the pattern of them. That's why it can also do, Trump and Biden, it knows what they look like. 

7. To the extent that it informs your views, please briefly describe your personal knowledge of the process by which AI models are trained. The Office is particularly interested in:  Well, I too interest in AI before I really understood what it was. A few of my favourite artists used it to create some of their own works by a color palette and using their name in SD or MJ. Once I started using it, I got involved on how they were able to do what it does and I became very uncomfortable.  I found one of my own works in the SD model on haveibeentrained.  It was a piece for myself and was from Deviantart.  I deleted the image, despite me not wanting to and it says they remove it but I don't know if it has. 

7.1. How are training materials used and/or reproduced when training an AI model? Please include your understanding of the nature and duration of any reproduction of works that occur during the training process, as well as your views on the extent to which these activities implicate the exclusive rights of copyright owners. Ai is trained by showing it tons of examples of things. They'll have a lot of different images/whatever of the same thing so it know what something looks like, for example a cat. It's not once, but a bunch of times. So, you would need a professional artist's entire body of work to be able to recall their style. This allows people who use AI to exploit artists by training on a specific artist, recalling their style and selling it as their own as people often think these ai works are from the specific artist. 

7.2. How are inferences gained from the training process stored or represented within an AI model? AI model stores the things it learned during training in different compartments inside itself. When we give it a new example, it looks at those compartments to find the right information and uses it to give an answer. So, while it doesn't have a image storing thing, it does have a memory, somehow of these copyrighted images. 

7.3. Is it possible for an AI model to “unlearn” inferences it gained from training on a particular piece of training material? If so, is it economically feasible? In addition to retraining a model, are there other ways to “unlearn” inferences from training? Yes, but it requires retraining. Retraining is expensive and that's why these companies do not want to retrain their model, despite it being parasitic to artists and sold at a premium. 

7.4. Absent access to the underlying dataset, is it possible to identify whether an AI model was trained on a particular piece of training material? Yes and no. It's difficult for researchers to directly identify but it's more of a guess but due to enough people using these generators, it has been found out that making a similar prompt will bring up the image the prompt has in common that belongs to an artist. 

8. Under what circumstances would the unauthorized use of copyrighted works to train AI models constitute fair use? Please discuss any case law you believe relevant to this question. 

8.1. In light of the Supreme Court's recent decisions in Google v. Oracle America   (41) and Andy Warhol Foundation v. Goldsmith, (42) how should the “purpose and character” of the use of copyrighted works to train an AI model be evaluated? What is the relevant use to be analyzed? Do different stages of training, such as pre-training and fine-tuning, (43) raise different considerations under the first fair use factor?  

8.2. How should the analysis apply to entities that collect and distribute copyrighted material for training but may not themselves engage in the training? Anyone collecting and distributing copyrighted works for training AI should prioitize respecting the artist's right and obtain permission. Artists should be supported if these AI companies are going to keep scraping. It is well known that many artists are choose to avoid posting their work at all or giving up completely to stop AI from continuously training without payment or permission. 

8.3. The use of copyrighted materials in a training dataset or to train generative AI models may be done for noncommercial or research purposes. (44) How should the fair use analysis apply if AI models or datasets are later adapted for use of a commercial nature?  (45) Does it make a difference if funding for these noncommercial or research uses is provided by for-profit developers of AI systems? These models should be retrained for commercial use, especially if their path is to never pay an artist for the work in the machine. They plan to sell this service as a premium, so I think retraining on non-copyrighted material should be easy. Research AI is different from Commercial. Commercial AI works are here to replace artists, not help them. 


8.5. Under the fourth factor of the fair use analysis, how should the effect on the potential market for or value of a copyrighted work used to train an AI model be measured?  (46) Should the inquiry be whether the outputs of the AI system incorporating the model compete with a particular copyrighted work, the body of works of the same author, or the market for that general class of works? When evaluating the effect on the market for a copyrighted work used to train an AI model, it is important to consider whether the outputs of the AI system compete with the original work, the works by the same author, or the market for similar works. A lot of ai content released can compete in those artists spaces, sometimes directly with the artist, diminishing value. Making all AI work content copyrightable directly effects the market for artists either freelance or otherwise, hurting future artists and up-and-coming. This harm's the artist ability to benefit from their own creations, this would not happen in the music industry -- why does it happen with artists?


9. Should copyright owners have to affirmatively consent (opt in) to the use of their works for training materials, or should they be provided with the means to object (opt out)? Artists should have the option of doing both, some would be glad to let their works be trained on and other don't. It needs to be both, otherwise it's the issue we are dealing with all over again. 

9.1. Should consent of the copyright owner be required for all uses of copyrighted works to train AI models or only commercial uses?  (47) Yes.

9.2. If an “opt out” approach were adopted, how would that process work for a copyright owner who objected to the use of their works for training? Are there technical tools that might facilitate this process, such as a technical flag or metadata indicating that an automated service should not collect and store a work for AI training uses?  (48) Well, perhaps a DRM could be put on the image and nomatter how or where it's posted that these images remain with copyright and either flagged not for use or deemed 'useable'.  

9.3. What legal, technical, or practical obstacles are there to establishing or using such a process? Given the volume of works used in training, is it feasible to get consent in advance from copyright owners? Yes, prior to training there can definitely be a notification process. They scraped from popular artist posting location like Deviantart, Artstation, Etc.  These websites can be notified prior to beginning training, apple something so these works are not a part of the scrape for the duration of the scraping.  

9.4. If an objection is not honored, what remedies should be available? Are existing remedies for infringement appropriate or should there be a separate cause of action? Given the unique nature of AI training and the potential impact on artists' works, the need for tailored remedies that specifically address the challenges and complexities of AI-related infringements. There should be damages, which is normal, something more serious if they keep removing consent, like the dismantilation of the model, this keeps these AI companies honest because they are NOT honest. We don't want to take away from ai content creators and new transformative works but if consent is a problem then a stronger consent rule should be necessary and enforced enough to inhibit the parasitic relationship that is current. Streaming made pirating videos/music too time consuming, while paying artists still on these platforms I am sure something can be done to protect artist while allowing new works. 

9.5. In cases where the human creator does not own the copyright—for example, because they have assigned it or because the work was made for hire—should they have a right to object to an AI model being trained on their work? If so, how would such a system work? I don't know, that's hard to say but if they use official works, it doesn't mean that you can go find the artist and take thier entire library of works because they worked on 1 project 3 yrs ago. 

10. If copyright owners' consent is required to train generative AI models, how can or should licenses be obtained? It should be public knowledge, they are scraping from websites. These websites are to be informed prior to the scrape, perhaps something to hide the account during that scrape.  If they want to use a body of work then they should go directly to the artist and pay a lump sum or royalties per generation on the companies paid plan. These are corporate entities, they do not care about to individual, only money and money should not be something you should make from AI. There should be no new billionares from this race if it truly is a new 'public good'. A new 'public good' shouldn't be hurting a massive amount of people who the technology is based off of. I am aware that this technology is not a public good but I feel that it's getting a lot of treatment as such. 

10.1. Is direct voluntary licensing feasible in some or all creative sectors? You can easily get in contact with artists directly, saying you cannot is 100% a lie. 

10.2. Is a voluntary collective licensing scheme a feasible or desirable approach?  (49) Are there existing collective management organizations that are well-suited to provide those licenses, and are there legal or other impediments that would prevent those organizations from performing this role? Should Congress consider statutory or other changes, such as an antitrust exception, to facilitate negotiation of collective licenses? To prioritize artists over billionaires, advocate for a voluntary collective licensing scheme that focuses on fair and direct compensation for artists, fair isn't a few cents as many of these works took 10-20 hours or more to complete but not all of them, some took less than 30 minutes. Create organizations that support artists specifically and promote transparent royalty distribution. Push for provisions that empower artists in negotiations, bypassing intermediaries that may favor billionaires. Artists often pay for the aid of other artists, would this not be an easier way for artists to make money and keep billionares from making more?

10.3. Should Congress consider establishing a compulsory licensing regime?  (50) If so, what should such a regime look like? What activities should the license cover, what works would be subject to the license, and would copyright owners have the ability to opt out? How should royalty rates and terms be set, allocated, reported and distributed? If Congress considers establishing a compulsory licensing regime, it should have clear limitations on the activities covered. The license should be narrowly defined to specific uses, ensuring that it does not unduly infringe upon the rights of copyright owners. It is important to advocate for a regime that does not enable wholesale unauthorized use or exploitation of artists' works. To protect artists' control over their works, it is paramount to include an opt-out provision. Copyright owners should have say in whether to participate in the compulsory licensing regime or retain exclusive control over their works.  The whole reason our works were scraped was because we have no automomy over our copyrighted works, that should never be a thing again. If we are using royalties: Setting fair and reasonable royalty rates and terms is of utmost importance. It is crucial to ensure that artists receive adequate compensation for the use of their works under the compulsory license. The rates and terms should be decided through a transparent and inclusive process, involving input from artists, industry experts, and relevant stakeholders -- not just billionares and tech guys. 

10.4. Is an extended collective licensing scheme  (51) a feasible or desirable approach? I think so but these liscenses should not be life licenses. 

10.5. Should licensing regimes vary based on the type of work at issue? Probably. 

11. What legal, technical or practical issues might there be with respect to obtaining appropriate licenses for training? Who, if anyone, should be responsible for securing them (for example when the curator of a training dataset, the developer who trains an AI model, and the company employing that model in an AI system are different entities and may have different commercial or noncommercial roles)? From an artist perspective, it is crucial to ensure that the rights of copyright owners are respected and that artists receive fair compensation. Clear agreements and contractual arrangements should determine licensing responsibilities among dataset curators, developers, and employing companies. The entity with the most control over the training process should bear the primary responsibility for securing licenses. Compliance and tracking mechanisms are necessary to monitor and report the use of copyrighted works during training. 

12. Is it possible or feasible to identify the degree to which a particular work contributes to a particular output from a generative AI system? Please explain. I think I explained it in my answer above. Basically, it's hard to find it but it can be found with techniques, if you know it was trained on a specific artists work, also overfitting. 

13. What would be the economic impacts of a licensing requirement on the development and adoption of generative AI systems? Implementing a licensing requirement for generative AI systems has positive economic impacts from a pro-artist stance. It ensures fair compensation for artists, stimulates creativity and innovation, expands the market for artists' works, encourages collaboration, and promotes ethical AI practices. It will, however, have an expense cost for the companies that are interested in training. It sounds unrealistic but the sheer amount of money used in the creation of the programs for use could have allocated money and lowered the volume of copyright content it took from. It's possible to make a public domain model, so it's possible to get lisencing. 

14. Please describe any other factors you believe are relevant with respect to potential copyright liability for training AI models. By keeping all 100% AI works allowed from copyright, this ensures the need for artists will never go away. Art should never be something only billionares can afford to do in their lifetime. AI companies are punching down on artists, Artists are punching up. Techies enjoy this tech because they can express themselves but many are not happy only doing that, they want to make money off these creations too. If they are going to do that and companies are going to use these AI companies they artists need to get paid too and not just 10-15 cents. 


Transparency & Recordkeeping

15. In order to allow copyright owners to determine whether their works have been used, should developers of AI models be required to collect, retain, and disclose records regarding the materials used to train their models? Should creators of training datasets have a similar obligation? Yes and Yes. Nothing should be hidden here. 

15.1. What level of specificity should be required? The name of the artist and which works.

15.2. To whom should disclosures be made? The artists. 

15.3. What obligations, if any, should be placed on developers of AI systems that incorporate models from third parties? They need to be transparent. When it comes to humanity vs AI, nothing should be hidden from humanity in regards to how it works or what works are put into it. 

15.4. What would be the cost or other impact of such a recordkeeping system for developers of AI models or systems, creators, consumers, or other relevant parties? I don't know. 

16. What obligations, if any, should there be to notify copyright owners that their works have been used to train an AI model?  Email, text, etc. There should be a notificaition. 

17. Outside of copyright law, are there existing U.S. laws that could require developers of AI models or systems to retain or disclose records about the materials they used for training? No idea. 

Generative AI Outputs

If your comment applies only to a particular subset of generative AI technologies, please make that clear.

Copyrightability

18. Under copyright law, are there circumstances when a human using a generative AI system should be considered the “author” of material produced by the system? If so, what factors are relevant to that determination? For example, is selecting what material an AI model is trained on and/or providing an iterative series of text commands or prompts sufficient to claim authorship of the resulting output?  Significant human output, meaning that the image cannot be 100% AI. Many users do a light suggestion in photoshop and run it through AI over and AI instead of making their own imprint on the piece. 
 
19. Are any revisions to the Copyright Act necessary to clarify the human authorship requirement or to provide additional standards to determine when content including AI-generated material is subject to copyright protection?  Currently, AI works cannot be copyrighted because there is no human authorship. I'd like it to stay that way.  I would say that a 10% AI/90% human authorship, meaning AI was in a support role and not the main feature. 

20. Is legal protection for AI-generated material desirable as a policy matter? Is legal protection for AI-generated material necessary to encourage development of generative AI technologies and systems? Does existing copyright protection for computer code that operates a generative AI system provide sufficient incentives? I have no idea, but definitely not for AI-related video or images. 

20.1. If you believe protection is desirable, should it be a form of copyright or a separate sui generis right? If the latter, in what respects should protection for AI-generated material differ from copyright? N/A

21. Does the Copyright Clause in the U.S. Constitution permit copyright protection for AI-generated material? Would such protection “promote the progress of science and useful arts”?  (52) If so, how? Under so circumstances should 100% Ai content be allowed to make money. As I said before, it is literally removing the downstream for real artists, which the entire machine is based on. On top of that, people making money off their AI images is already a thing and these people frequently have tech jobs and have expensive PCs to do this. These types do not need copyright protection for their ai works to be sold as a side hustle to their main hustle that gains them over 200k a year. 

Infringement

22. Can AI-generated outputs implicate the exclusive rights of preexisting copyrighted works, such as the right of reproduction or the derivative work right? If so, in what circumstances? Yes it can, they can unintentionall incorporate substanial portions of a preexisting copyrighted work. It can infringe on the rights of the artist to reproduce that work. 

23. Is the substantial similarity test adequate to address claims of infringement based on outputs from a generative AI system, or is some other standard appropriate or necessary? Overreliance on technical statistical measures of distance between outputs versus works could undervalue contextual, cultural factors in assessing similarity. A holistic approach assessing both technical and interpretive factors is prudent. AI art directly competing in commercial contexts where a human creator distributes similar genre work may constitute market harm even if technical dissimilarity exists. Financial impacts on creators need weighting beyond just visual comparisons. Strictly pixel-level assessment misses derivative stylistic elements.As AI capabilities gets better, overemphasizing technical dissimilarity from any one existing work risks missing the bigger picture of models extensively borrowing elements from human artists over time.

24. How can copyright owners prove the element of copying (such as by demonstrating access to a copyrighted work) if the developer of the AI model does not maintain or make available records of what training material it used? Are existing civil discovery rules sufficient to address this situation? Shift the burden of proof - require companies prove training data did NOT include copyrighted material rather than rights holders proving it did. Lack of records would fail this test. 

25. If AI-generated material is found to infringe a copyrighted work, who should be directly or secondarily liable—the developer of a generative AI model, the developer of the system incorporating that model, end users of the system, or other parties?  Developer of the AI model, also end user if they are parading as that artist. 

25.1. Do “open-source” AI models raise unique considerations with respect to infringement based on their outputs?  (53) Yes, because they scrape just like the rest of them. They allow more infrigment, actually. 

26. If a generative AI system is trained on copyrighted works containing copyright management information, how does 17 U.S.C. 1202(b) apply to the treatment of that information in outputs of the system? 

27. Please describe any other issues that you believe policymakers should consider with respect to potential copyright liability based on AI-generated output. There should be no reason why AI should be the end part of the artist process.  It is fitted with too many issues, it's embarassing and companies have money to pay artists, this takes away their livelihood and tells the world that they don't need artists, even for jobs that are exclusively theirs.  A generated idea is different than AI all the way through the process. 

Labeling or Identification

28. Should the law require AI-generated material to be labeled or otherwise publicly identified as being generated by AI? If so, in what context should the requirement apply and how should it work?  Yes. There should be a prominant marker remaining on the image if it's just AI. I'm not talking about someone who worked on an AI image where you can no longer see it's AI. Perhaps, in search engines, we could use a small [ai] in the bottom right corner and like adobe and deviantart does google and institute a 'avoid ai' while searching. We need to be able to search images without 300 images that are AI in the search because of the droves of it. 

28.1. Who should be responsible for identifying a work as AI-generated? Search engines, AI developers. 

28.2. Are there technical or practical barriers to labeling or identification requirements? I don't think so, not that I know of. Deviantart already has a detector, we just need better ones to label ai. 

28.3. If a notification or labeling requirement is adopted, what should be the consequences of the failure to label a particular work or the removal of a label? It should be able to be reported or users can suggest to put the AI tag on it. 

29. What tools exist or are in development to identify AI-generated material, including by standard-setting bodies? How accurate are these tools? What are their limitations? Hive AI detection is all I know.  It's not 100% but should be 90%, I'd say it's closer to 70/30.  It never says human work is not human work but it will, sometimes, say that ai is partially human. 

Additional Questions About Issues Related to Copyright

30. What legal rights, if any, currently apply to AI-generated material that features the name or likeness, including vocal likeness, of a particular person? I don't think there are any but there should be extensive rights that people get to keep their autonmy. 

31. Should Congress establish a new federal right, similar to state law rights of publicity, that would apply to AI-generated material? If so, should it preempt state laws or set a ceiling or floor for state law protections? What should be the contours of such a right? Just because you are a public figure doesn't mean that you can have people use your likeness or voice anyway they want. I don't know about the rest of this but congress should establish the floor that using someone likeness in AI is not alright without premission. 

32. Are there or should there be protections against an AI system generating outputs that imitate the artistic style of a human creator (such as an AI system producing visual works “in the style of” a specific artist)? Who should be eligible for such protection? What form should it take?  In the style of should be completely removed from AI generators. There should be only generic words that are not going to infringe like anime, soft colors, etc. Artistic styles are like a fingerprint to the person, despite it not being copyright, it could infringe or compete directly with that specific artist. 

33. With respect to sound recordings, how does section 114(b) of the Copyright Act relate to state law, such as state right of publicity laws?  (54) Does this issue require legislative attention in the context of generative AI? Preemption of state publicity laws risks AI developers exploiting loopholes and infringing on artists' rights. Updating legislation should fix this. Also, upholding publlicity rights against unauthorized ai imitation would protect performs and ai companies cannot ignore state law.  They should be carved out to allow commentary content, parody content and preserve free speech.  Any new guardrails for AI much safeguard fair use. Close the loopholes for Ai because they will exploit them and for monetary gain. 


34. Please identify any issues not mentioned above that the Copyright Office should consider in conducting this study: 
1. How copyright applies to hybrid works blending human and AI contributions
2. Effects on parody and sature. 
3. Standards to stop the spread of misinformation
4. Effects on archival institutions like libraries using AI
5. Guidelines for disclosing how AI generation is involved in public works.
6. Fixing for AI bias to prevent issues for marginlized groups.